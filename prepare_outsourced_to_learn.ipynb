{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "\n",
    "Plan - Acquire - Prepare - Explore - Model - Deliver\n",
    "\n",
    "What we are doing and why:\n",
    "What: Clean and tidy our data so that it is ready for exploration, analysis and modeling\n",
    "\n",
    "Why: Set ourselves up for certainty!\n",
    "\n",
    "1) Ensure that our observations will be sound:\n",
    "    Validity of statistical and human observations\n",
    "2) Ensure that we will not have computational errors:\n",
    "    non numerical data cells, nulls/NaNs\n",
    "3) Protect against overfitting:\n",
    "    Ensure that have a split data structure prior to drawing conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level Roadmap:\n",
    "\n",
    "Input: An aquired dataset (One Pandas Dataframe) ------> Output: Tidied and cleaned data split into Train,  Validate, and Test sets (Three Pandas Dataframes)\n",
    "Processes: Summarize the data ---> Clean the data ---> Split the dataÂ¶\n",
    "\n",
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import acquire as aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our acquired dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  891 non-null    int64  \n",
      " 1   survived      891 non-null    int64  \n",
      " 2   pclass        891 non-null    int64  \n",
      " 3   sex           891 non-null    object \n",
      " 4   age           714 non-null    float64\n",
      " 5   sibsp         891 non-null    int64  \n",
      " 6   parch         891 non-null    int64  \n",
      " 7   fare          891 non-null    float64\n",
      " 8   embarked      889 non-null    object \n",
      " 9   class         891 non-null    object \n",
      " 10  deck          203 non-null    object \n",
      " 11  embark_town   889 non-null    object \n",
      " 12  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <td>891.0</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.00</td>\n",
       "      <td>222.5000</td>\n",
       "      <td>445.0000</td>\n",
       "      <td>667.5</td>\n",
       "      <td>890.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std   min       25%       50%    75%  \\\n",
       "passenger_id  891.0  445.000000  257.353842  0.00  222.5000  445.0000  667.5   \n",
       "survived      891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "pclass        891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "age           714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "sibsp         891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "parch         891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "fare          891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "alone         891.0    0.602694    0.489615  0.00    0.0000    1.0000    1.0   \n",
       "\n",
       "                   max  \n",
       "passenger_id  890.0000  \n",
       "survived        1.0000  \n",
       "pclass          3.0000  \n",
       "age            80.0000  \n",
       "sibsp           8.0000  \n",
       "parch           6.0000  \n",
       "fare          512.3292  \n",
       "alone           1.0000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'survived', 'pclass', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = df.select_dtypes(np.number).columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'embarked', 'class', 'deck', 'embark_town'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols = df.select_dtypes(np.object).columns\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe our object columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      577\n",
      "female    314\n",
      "Name: sex, dtype: int64 \n",
      "\n",
      "~~~~~\n",
      "\n",
      "male      0.647587\n",
      "female    0.352413\n",
      "Name: sex, dtype: float64 \n",
      "\n",
      "- - -\n",
      "\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: embarked, dtype: int64 \n",
      "\n",
      "~~~~~\n",
      "\n",
      "S      0.722783\n",
      "C      0.188552\n",
      "Q      0.086420\n",
      "NaN    0.002245\n",
      "Name: embarked, dtype: float64 \n",
      "\n",
      "- - -\n",
      "\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: class, dtype: int64 \n",
      "\n",
      "~~~~~\n",
      "\n",
      "Third     0.551066\n",
      "First     0.242424\n",
      "Second    0.206510\n",
      "Name: class, dtype: float64 \n",
      "\n",
      "- - -\n",
      "\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: deck, dtype: int64 \n",
      "\n",
      "~~~~~\n",
      "\n",
      "NaN    0.772166\n",
      "C      0.066218\n",
      "B      0.052750\n",
      "D      0.037037\n",
      "E      0.035915\n",
      "A      0.016835\n",
      "F      0.014590\n",
      "G      0.004489\n",
      "Name: deck, dtype: float64 \n",
      "\n",
      "- - -\n",
      "\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: embark_town, dtype: int64 \n",
      "\n",
      "~~~~~\n",
      "\n",
      "Southampton    0.722783\n",
      "Cherbourg      0.188552\n",
      "Queenstown     0.086420\n",
      "NaN            0.002245\n",
      "Name: embark_town, dtype: float64 \n",
      "\n",
      "- - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe object columns\n",
    "for col in obj_cols:\n",
    "    print(df[col].value_counts(), '\\n\\n~~~~~\\n')\n",
    "    print(df[col].value_counts(normalize = True, dropna = False), '\\n\\n- - -\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            177\n",
       "embarked         2\n",
       "deck           688\n",
       "embark_town      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "missing = df.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gather our takeaways, i.e., what we are going to do when we clean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. embarked == embark_town. Pick one to keep since they are dupicates. We'll keep embarked_town for now since it is more human readable.\n",
    "\n",
    "2. class == pclass. They say the same thing, so let's keep the one that is numerical.\n",
    "\n",
    "3. deck and age have many missing values. Deck will be of no use to us with that many missing values and we will say the same of age without more insight. We will drop these columns.\n",
    "\n",
    "4. We have just two values missing from embark_town, and we will fill these in with the most common embark_town category\n",
    "\n",
    "5. For embark_town and sex, we will encode the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates...run just in case\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with too many missing to have any value right now\n",
    "df.drop(columns=['deck', 'age', 'embarked', 'class'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could fill embark_town with most common value, 'Southampton', by hard-coding the value using the fillna() function, as below. Or we could use an imputer. We will demonstrate the imputer after the train-validate-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embark_town.fillna(value = 'Southampton', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  891 non-null    int64  \n",
      " 1   survived      891 non-null    int64  \n",
      " 2   pclass        891 non-null    int64  \n",
      " 3   sex           891 non-null    object \n",
      " 4   sibsp         891 non-null    int64  \n",
      " 5   parch         891 non-null    int64  \n",
      " 6   fare          891 non-null    float64\n",
      " 7   embark_town   891 non-null    object \n",
      " 8   alone         891 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(2)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             891 non-null    int64  \n",
      " 1   survived                 891 non-null    int64  \n",
      " 2   pclass                   891 non-null    int64  \n",
      " 3   sex                      891 non-null    object \n",
      " 4   sibsp                    891 non-null    int64  \n",
      " 5   parch                    891 non-null    int64  \n",
      " 6   fare                     891 non-null    float64\n",
      " 7   embark_town              891 non-null    object \n",
      " 8   alone                    891 non-null    int64  \n",
      " 9   sex_male                 891 non-null    uint8  \n",
      " 10  embark_town_Queenstown   891 non-null    uint8  \n",
      " 11  embark_town_Southampton  891 non-null    uint8  \n",
      "dtypes: float64(1), int64(6), object(2), uint8(3)\n",
      "memory usage: 72.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make that into a function so we can repeat it all easily in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_titanic_data() got an unexpected keyword argument 'force_cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ca61daa15a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_titanic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_titanic_data() got an unexpected keyword argument 'force_cache'"
     ]
    }
   ],
   "source": [
    "df = aq.get_titanic_data(force_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titanic_data(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop(columns=['deck', 'age', 'embarked', 'class'])\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df.drop(columns=['sex', 'embark_town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_v0 = clean_titanic_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_v0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to perform these steps when we need to reproduce our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_df_v0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7b3998295910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 20% test, 80% train_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# then of the 80% train_validate: 30% validate, 70% train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_df_v0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcleaned_df_v0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_df_v0' is not defined"
     ]
    }
   ],
   "source": [
    "# 20% test, 80% train_validate\n",
    "# then of the 80% train_validate: 30% validate, 70% train. \n",
    "train, test = train_test_split(cleaned_df_v0, test_size=0.2, random_state=19, stratify=cleaned_df_v0.survived)\n",
    "train, validate = train_test_split(train, test_size=0.3, random_state=19, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option for Missing Values: Impute\n",
    "\n",
    "We can impute values using the mean, median, mode (most frequent), or a constant value. We will use sklearn.imputer.SimpleImputer to do this.\n",
    "\n",
    "1. Create the imputer object, selecting the strategy used to impute (mean, median or mode (strategy = 'most_frequent').\n",
    "\n",
    "2. Fit to train. This means compute the mean, median, or most_frequent (i.e. mode) for each of the columns that will be imputed. Store that value in the imputer object.\n",
    "\n",
    "3. Transform train: fill missing values in train dataset with that value identified\n",
    "\n",
    "4. Transform test: fill missing values with that value identified\n",
    "\n",
    "##### 1. Create the SimpleImputer object, which we will store in the variable imputer. In the creation of the object, we will specify the strategy to use (mean, median, most_frequent). Essentially, this is creating the instructions and assigning them to a variable we will reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the imputer to the columns in the training df. This means that the imputer will determine the most_frequent value, or other value depending on the strategy called, for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2d667de141aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imputer' is not defined"
     ]
    }
   ],
   "source": [
    "imputer = imputer.fit(df[['embark_town']])\n",
    "imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleImputer(missing_values=None, strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will store that value in the imputer object to use upon calling transform. We will call transform on each of our samples to fill any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-681e3388f1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imputer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train[['embark_town']] = imputer.transform(train[['embark_town']])\n",
    "validate[['embark_town']] = imputer.transform(validate[['embark_town']])\n",
    "test[['embark_town']] = imputer.transform(test[['embark_town']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will run through all of these steps, when I provide a train and test dataframe, a strategy, and a list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_mode(train, validate, test):\n",
    "    imputer = SimpleImputer(missing_values=None, strategy='most_frequent')\n",
    "    train[['embark_town']] = imputer.fit_transform(train[['embark_town']])\n",
    "    validate[['embark_town']] = imputer.transform(validate[['embark_town']])\n",
    "    test[['embark_town']] = imputer.transform(test[['embark_town']])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blend the clean, split and impute functions into a single prep_data() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic_data(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop(columns=['passenger_id', 'deck', 'age', 'embarked', 'class'])\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=19, stratify=df.survived)\n",
    "    train, validate = train_test_split(train, test_size=0.3, random_state=19, stratify=train.survived)\n",
    "    train, validate, test = impute_mode(train, validate, test)\n",
    "    \n",
    "    dummy_train = pd.get_dummies(train[['sex', 'embark_town']], drop_first=True)\n",
    "    dummy_validate = pd.get_dummies(validate[['sex', 'embark_town']], drop_first=True)\n",
    "    dummy_test = pd.get_dummies(test[['sex', 'embark_town']], drop_first=True)\n",
    "    \n",
    "    train = pd.concat([train, dummy_train], axis=1)\n",
    "    validate = pd.concat([validate, dummy_validate], axis=1)\n",
    "    test = pd.concat([test, dummy_test], axis=1)\n",
    "    \n",
    "    train = train.drop(columns=['sex', 'embark_town'])\n",
    "    validate = validate.drop(columns=['sex', 'embark_town'])\n",
    "    test = test.drop(columns=['sex', 'embark_town'])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep_titanic_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.488073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>179.0</td>\n",
       "      <td>2.312849</td>\n",
       "      <td>0.849588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>1.118237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.296089</td>\n",
       "      <td>0.761825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>179.0</td>\n",
       "      <td>30.212358</td>\n",
       "      <td>44.698635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.462653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.473383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.083799</td>\n",
       "      <td>0.277863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.449928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count       mean        std  min     25%   50%   75%  \\\n",
       "survived                 179.0   0.385475   0.488073  0.0  0.0000   0.0   1.0   \n",
       "pclass                   179.0   2.312849   0.849588  1.0  1.5000   3.0   3.0   \n",
       "sibsp                    179.0   0.469274   1.118237  0.0  0.0000   0.0   1.0   \n",
       "parch                    179.0   0.296089   0.761825  0.0  0.0000   0.0   0.0   \n",
       "fare                     179.0  30.212358  44.698635  0.0  7.8958  13.0  30.0   \n",
       "alone                    179.0   0.692737   0.462653  0.0  0.0000   1.0   1.0   \n",
       "sex_male                 179.0   0.664804   0.473383  0.0  0.0000   1.0   1.0   \n",
       "embark_town_Queenstown   179.0   0.083799   0.277863  0.0  0.0000   0.0   0.0   \n",
       "embark_town_Southampton  179.0   0.720670   0.449928  0.0  0.0000   1.0   1.0   \n",
       "\n",
       "                           max  \n",
       "survived                   1.0  \n",
       "pclass                     3.0  \n",
       "sibsp                      8.0  \n",
       "parch                      5.0  \n",
       "fare                     263.0  \n",
       "alone                      1.0  \n",
       "sex_male                   1.0  \n",
       "embark_town_Queenstown     1.0  \n",
       "embark_town_Southampton    1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
